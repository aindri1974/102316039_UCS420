{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgJClgtUQsuD4ncY6cy3Xj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aindri1974/102316039_UCS420/blob/main/102316039_Assignment_9_Aindri_Singh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab Assignment 9\n",
        "\n",
        "Assignment Title: NLP using Python"
      ],
      "metadata": {
        "id": "er2lF0rwxDkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
        "technology, food, books, etc.).\n",
        "1. Convert text to lowercase and remove punctuation.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Remove stopwords (using NLTK's stopwords list).\n",
        "4. Display word frequency distribution (excluding stopwords).\n"
      ],
      "metadata": {
        "id": "g_DxijdQxStQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')  # Adding this to fix the error\n",
        "\n",
        "sample_text = \"\"\"\n",
        "Artificial Intelligence is transforming modern technology. AI systems can now understand natural language, recognize images, and make decisions. Machine learning algorithms learn from data without explicit programming. Deep learning uses neural networks with many layers. AI applications include chatbots, self-driving cars, and medical diagnosis. The future of AI promises even more amazing breakthroughs.\n",
        "\"\"\"\n",
        "\n",
        "text_lower = sample_text.lower()\n",
        "text_no_punct = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
        "words = word_tokenize(text_no_punct)\n",
        "sentences = sent_tokenize(sample_text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "fdist = FreqDist(filtered_words)\n",
        "\n",
        "print(\"Processed Text:\")\n",
        "print(text_no_punct)\n",
        "print(\"\\nTokenized Sentences:\")\n",
        "for i, sentence in enumerate(sentences, 1):\n",
        "    print(f\"{i}. {sentence}\")\n",
        "print(\"\\nFiltered Words:\")\n",
        "print(filtered_words)\n",
        "print(\"\\nWord Frequency:\")\n",
        "print(fdist.most_common())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hPuuj_T-3y6",
        "outputId": "bda7c258-ea7c-435d-b117-5ebad69f231e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text:\n",
            "\n",
            "artificial intelligence is transforming modern technology ai systems can now understand natural language recognize images and make decisions machine learning algorithms learn from data without explicit programming deep learning uses neural networks with many layers ai applications include chatbots selfdriving cars and medical diagnosis the future of ai promises even more amazing breakthroughs\n",
            "\n",
            "\n",
            "Tokenized Sentences:\n",
            "1. \n",
            "Artificial Intelligence is transforming modern technology.\n",
            "2. AI systems can now understand natural language, recognize images, and make decisions.\n",
            "3. Machine learning algorithms learn from data without explicit programming.\n",
            "4. Deep learning uses neural networks with many layers.\n",
            "5. AI applications include chatbots, self-driving cars, and medical diagnosis.\n",
            "6. The future of AI promises even more amazing breakthroughs.\n",
            "\n",
            "Filtered Words:\n",
            "['artificial', 'intelligence', 'transforming', 'modern', 'technology', 'ai', 'systems', 'understand', 'natural', 'language', 'recognize', 'images', 'make', 'decisions', 'machine', 'learning', 'algorithms', 'learn', 'data', 'without', 'explicit', 'programming', 'deep', 'learning', 'uses', 'neural', 'networks', 'many', 'layers', 'ai', 'applications', 'include', 'chatbots', 'selfdriving', 'cars', 'medical', 'diagnosis', 'future', 'ai', 'promises', 'even', 'amazing', 'breakthroughs']\n",
            "\n",
            "Word Frequency:\n",
            "[('ai', 3), ('learning', 2), ('artificial', 1), ('intelligence', 1), ('transforming', 1), ('modern', 1), ('technology', 1), ('systems', 1), ('understand', 1), ('natural', 1), ('language', 1), ('recognize', 1), ('images', 1), ('make', 1), ('decisions', 1), ('machine', 1), ('algorithms', 1), ('learn', 1), ('data', 1), ('without', 1), ('explicit', 1), ('programming', 1), ('deep', 1), ('uses', 1), ('neural', 1), ('networks', 1), ('many', 1), ('layers', 1), ('applications', 1), ('include', 1), ('chatbots', 1), ('selfdriving', 1), ('cars', 1), ('medical', 1), ('diagnosis', 1), ('future', 1), ('promises', 1), ('even', 1), ('amazing', 1), ('breakthroughs', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Stemming and Lemmatization\n",
        "1. Take the tokenized words from Question 1 (after stopword removal).\n",
        "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "3. Apply lemmatization using NLTK's WordNetLemmatizer.\n",
        "4. Compare and display results of both techniques."
      ],
      "metadata": {
        "id": "3Lea_2t1xaE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "porter_stems = [porter.stem(word) for word in filtered_words]\n",
        "lancaster_stems = [lancaster.stem(word) for word in filtered_words]\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "print(\"Original Words:\", filtered_words)\n",
        "print(\"\\nPorter Stemmer:\", porter_stems)\n",
        "print(\"\\nLancaster Stemmer:\", lancaster_stems)\n",
        "print(\"\\nLemmatization:\", lemmas)\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"{'Original':<15} {'Porter':<15} {'Lancaster':<15} {'Lemma'}\")\n",
        "for i in range(5):\n",
        "    print(f\"{filtered_words[i]:<15} {porter_stems[i]:<15} {lancaster_stems[i]:<15} {lemmas[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEtNei4U-8j7",
        "outputId": "8e9825ca-dcb0-4a4f-c479-45b77a17fa35"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Words: ['artificial', 'intelligence', 'transforming', 'modern', 'technology', 'ai', 'systems', 'understand', 'natural', 'language', 'recognize', 'images', 'make', 'decisions', 'machine', 'learning', 'algorithms', 'learn', 'data', 'without', 'explicit', 'programming', 'deep', 'learning', 'uses', 'neural', 'networks', 'many', 'layers', 'ai', 'applications', 'include', 'chatbots', 'selfdriving', 'cars', 'medical', 'diagnosis', 'future', 'ai', 'promises', 'even', 'amazing', 'breakthroughs']\n",
            "\n",
            "Porter Stemmer: ['artifici', 'intellig', 'transform', 'modern', 'technolog', 'ai', 'system', 'understand', 'natur', 'languag', 'recogn', 'imag', 'make', 'decis', 'machin', 'learn', 'algorithm', 'learn', 'data', 'without', 'explicit', 'program', 'deep', 'learn', 'use', 'neural', 'network', 'mani', 'layer', 'ai', 'applic', 'includ', 'chatbot', 'selfdriv', 'car', 'medic', 'diagnosi', 'futur', 'ai', 'promis', 'even', 'amaz', 'breakthrough']\n",
            "\n",
            "Lancaster Stemmer: ['art', 'intellig', 'transform', 'modern', 'technolog', 'ai', 'system', 'understand', 'nat', 'langu', 'recogn', 'im', 'mak', 'decid', 'machin', 'learn', 'algorithm', 'learn', 'dat', 'without', 'explicit', 'program', 'deep', 'learn', 'us', 'neur', 'network', 'many', 'lay', 'ai', 'apply', 'includ', 'chatbot', 'selfdr', 'car', 'med', 'diagnos', 'fut', 'ai', 'prom', 'ev', 'amaz', 'breakthrough']\n",
            "\n",
            "Lemmatization: ['artificial', 'intelligence', 'transforming', 'modern', 'technology', 'ai', 'system', 'understand', 'natural', 'language', 'recognize', 'image', 'make', 'decision', 'machine', 'learning', 'algorithm', 'learn', 'data', 'without', 'explicit', 'programming', 'deep', 'learning', 'us', 'neural', 'network', 'many', 'layer', 'ai', 'application', 'include', 'chatbots', 'selfdriving', 'car', 'medical', 'diagnosis', 'future', 'ai', 'promise', 'even', 'amazing', 'breakthrough']\n",
            "\n",
            "Comparison:\n",
            "Original        Porter          Lancaster       Lemma\n",
            "artificial      artifici        art             artificial\n",
            "intelligence    intellig        intellig        intelligence\n",
            "transforming    transform       transform       transforming\n",
            "modern          modern          modern          modern\n",
            "technology      technolog       technolog       technology\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Regular Expressions and Text Spliƫng\n",
        "1. Take their original text from Question 1.\n",
        "2. Use regular expressions to:\n",
        "\n",
        "a. Extract all words with more than 5 letters.\n",
        "\n",
        "b. Extract all numbers (if any exist in their text).\n",
        "\n",
        "c. Extract all capitalized words.\n",
        "3. Use text spliƫng techniques to:\n",
        "\n",
        "a. Split the text into words containing only alphabets (removing digits and special\n",
        "characters).\n",
        "\n",
        "b. Extract words starting with a vowel."
      ],
      "metadata": {
        "id": "SFi3GPAyxz5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "long_words = re.findall(r'\\b\\w{6,}\\b', sample_text)\n",
        "numbers = re.findall(r'\\b\\d+\\b', sample_text)\n",
        "capitalized = re.findall(r'\\b[A-Z][a-z]+\\b', sample_text)\n",
        "alpha_words = re.findall(r'\\b[a-zA-Z]+\\b', sample_text)\n",
        "vowel_words = re.findall(r'\\b[aeiouAEIOU][a-zA-Z]*\\b', sample_text)\n",
        "\n",
        "print(\"Words >5 letters:\", long_words)\n",
        "print(\"\\nNumbers:\", numbers)\n",
        "print(\"\\nCapitalized:\", capitalized)\n",
        "print(\"\\nAlpha words:\", alpha_words)\n",
        "print(\"\\nVowel-starting:\", vowel_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYfh593Z-Pdq",
        "outputId": "a317cee8-bc31-4149-986d-7a598eaae865"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words >5 letters: ['Artificial', 'Intelligence', 'transforming', 'modern', 'technology', 'systems', 'understand', 'natural', 'language', 'recognize', 'images', 'decisions', 'Machine', 'learning', 'algorithms', 'without', 'explicit', 'programming', 'learning', 'neural', 'networks', 'layers', 'applications', 'include', 'chatbots', 'driving', 'medical', 'diagnosis', 'future', 'promises', 'amazing', 'breakthroughs']\n",
            "\n",
            "Numbers: []\n",
            "\n",
            "Capitalized: ['Artificial', 'Intelligence', 'Machine', 'Deep', 'The']\n",
            "\n",
            "Alpha words: ['Artificial', 'Intelligence', 'is', 'transforming', 'modern', 'technology', 'AI', 'systems', 'can', 'now', 'understand', 'natural', 'language', 'recognize', 'images', 'and', 'make', 'decisions', 'Machine', 'learning', 'algorithms', 'learn', 'from', 'data', 'without', 'explicit', 'programming', 'Deep', 'learning', 'uses', 'neural', 'networks', 'with', 'many', 'layers', 'AI', 'applications', 'include', 'chatbots', 'self', 'driving', 'cars', 'and', 'medical', 'diagnosis', 'The', 'future', 'of', 'AI', 'promises', 'even', 'more', 'amazing', 'breakthroughs']\n",
            "\n",
            "Vowel-starting: ['Artificial', 'Intelligence', 'is', 'AI', 'understand', 'images', 'and', 'algorithms', 'explicit', 'uses', 'AI', 'applications', 'include', 'and', 'of', 'AI', 'even', 'amazing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Custom TokenizaƟon & Regex-based Text Cleaning\n",
        "1. Take original text from Question 1.\n",
        "2. Write a custom tokenization function that:\n",
        "a. Removes punctuation and special symbols, but keeps contractions (e.g.,\n",
        "\"isn't\" should not be split into \"is\" and \"n't\").\n",
        "b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains\n",
        "a single token).\n",
        "c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\"\n",
        "should remain as is).\n",
        "3. Use Regex Substitutions (re.sub) to:\n",
        "a. Replace email addresses with '<EMAIL>' placeholder.\n",
        "b. Replace URLs with '<URL>' placeholder.\n",
        "c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with\n",
        "'<PHONE>' placeholder."
      ],
      "metadata": {
        "id": "iEJuZ-uqyGNY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMI6b841w_5G",
        "outputId": "8f4ad348-eb3c-4251-b970-f034b11f85de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "\n",
            "Artificial Intelligence is transforming modern technology. AI systems can now understand natural language, recognize images, and make decisions. Machine learning algorithms learn from data without explicit programming. Deep learning uses neural networks with many layers. AI applications include chatbots, self-driving cars, and medical diagnosis. The future of AI promises even more amazing breakthroughs.\n",
            "\n",
            "Contact us at support@example.com or visit https://www.example.com.\n",
            "Call us at 123-456-7890 or +91 9876543210. State-of-the-art AI isn't easy.\n",
            "The value is 3.14 and version 2.0 is available.\n",
            "\n",
            "\n",
            "Custom Tokens:\n",
            "['Artificial', 'Intelligence', 'is', 'transforming', 'modern', 'technology', 'AI', 'systems', 'can', 'now', 'understand', 'natural', 'language', 'recognize', 'images', 'and', 'make', 'decisions', 'Machine', 'learning', 'algorithms', 'learn', 'from', 'data', 'without', 'explicit', 'programming', 'Deep', 'learning', 'uses', 'neural', 'networks', 'with', 'many', 'layers', 'AI', 'applications', 'include', 'chatbots', 'self', 'driving', 'cars', 'and', 'medical', 'diagnosis', 'The', 'future', 'of', 'AI', 'promises', 'even', 'more', 'amazing', 'breakthroughs', 'Contact', 'us', 'at', 'support', 'example', 'com', 'or', 'visit', 'https', 'www', 'example', 'com', 'Call', 'us', 'at', '123', '456', '7890', 'or', '91', '9876543210', 'State', 'of', 'the', 'art', 'AI', \"isn't\", 'easy', 'The', 'value', 'is', '3', '14', 'and', 'version', '2', '0', 'is', 'available']\n",
            "\n",
            "Cleaned Text:\n",
            "\n",
            "Artificial Intelligence is transforming modern technology. AI systems can now understand natural language, recognize images, and make decisions. Machine learning algorithms learn from data without explicit programming. Deep learning uses neural networks with many layers. AI applications include chatbots, self-driving cars, and medical diagnosis. The future of AI promises even more amazing breakthroughs.\n",
            "\n",
            "Contact us at <EMAIL> or visit <URL>\n",
            "Call us at <PHONE> or <PHONE>. State-of-the-art AI isn't easy.\n",
            "The value is 3.14 and version 2.0 is available.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_text = sample_text + \"\"\"\n",
        "Contact us at support@example.com or visit https://www.example.com.\n",
        "Call us at 123-456-7890 or +91 9876543210. State-of-the-art AI isn't easy.\n",
        "The value is 3.14 and version 2.0 is available.\n",
        "\"\"\"\n",
        "\n",
        "def custom_tokenize(text):\n",
        "    tokens = re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", text)\n",
        "    tokens = [token if '-' not in token else token for token in tokens]\n",
        "    tokens = [token if not re.match(r'^\\d+\\.\\d+$', token) else token for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "tokens = custom_tokenize(test_text)\n",
        "cleaned = re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b', '<EMAIL>', test_text)\n",
        "cleaned = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', cleaned)\n",
        "cleaned = re.sub(r'(\\+\\d{1,3}[- ]?)?\\d{3}[- ]?\\d{3}[- ]?\\d{4}\\b', '<PHONE>', cleaned)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(test_text)\n",
        "print(\"\\nCustom Tokens:\")\n",
        "print(tokens)\n",
        "print(\"\\nCleaned Text:\")\n",
        "print(cleaned)"
      ]
    }
  ]
}